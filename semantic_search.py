import sqlite3
import json
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import re
from typing import List, Dict, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIToolsSemanticSearch:
    def __init__(self, db_path='ai_tools_full.db'):
        self.db_path = db_path
        self.model = None
        self.tools_data = []
        self.embeddings = None
        
        # ×˜×¢×Ÿ ××•×“×œ embedding (×§×˜×Ÿ ×•××”×™×¨)
        logger.info("ğŸ¤– ×˜×•×¢×Ÿ ××•×“×œ ×¢×‘×¨×™×ª/×× ×’×œ×™×ª...")
        try:
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… ××•×“×œ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”")
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××•×“×œ: {e}")
            raise
        
        self.load_tools_from_db()
        self.setup_search_index()
    
    def load_tools_from_db(self):
        """×˜×¢×™× ×ª ×›×œ×™× ×××¡×“ ×”× ×ª×•× ×™×"""
        logger.info("ğŸ“Š ×˜×•×¢×Ÿ ×›×œ×™× ×××¡×“ ×”× ×ª×•× ×™×...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT name, url, description, category, popularity, pricing, tags 
                FROM ai_tools 
                WHERE description IS NOT NULL AND description != ""
                ORDER BY name
            ''')
            
            rows = cursor.fetchall()
            
            for row in rows:
                tool = {
                    'name': row[0] or '',
                    'url': row[1] or '', 
                    'description': row[2] or '',
                    'category': row[3] or '',
                    'popularity': row[4] or '',
                    'pricing': row[5] or '',
                    'tags': row[6] or ''
                }
                self.tools_data.append(tool)
            
            conn.close()

        except sqlite3.DatabaseError as e:
            logger.error(f"Database error loading data: {e}")
            raise
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª × ×ª×•× ×™×: {e}")
            # × ×™×¡×™×•×Ÿ ×¢× × ×ª×•× ×™× ×“××” ×× ××¡×“ ×”× ×ª×•× ×™× ×œ× ×–××™×Ÿ
            self.tools_data = [
                {
                    'name': 'ChatGPT',
                    'url': 'https://www.aixploria.com/en/chatgpt/',
                    'description': 'Advanced AI chatbot for conversations and text generation.',
                    'category': 'Text Generation',
                    'popularity': '+15840',
                    'pricing': 'freemium',
                    'tags': 'chat, AI, conversation'
                },
                {
                    'name': 'MidJourney',
                    'url': 'https://www.aixploria.com/en/midjourney/',
                    'description': 'AI image generator that creates stunning artwork from text prompts.',
                    'category': 'Image Generation',
                    'popularity': '+12453',
                    'pricing': 'paid',
                    'tags': 'image, art, generation'
                }
            ]
        
        logger.info(f"âœ… × ×˜×¢× ×• {len(self.tools_data)} ×›×œ×™ AI")
        
        if len(self.tools_data) == 0:
            logger.warning("âš ï¸ ×œ× × ××¦××• ×›×œ×™× - ××©×ª××© ×‘× ×ª×•× ×™× ×“××”")
    
    def create_search_text(self, tool):
        """×™×¦×™×¨×ª ×˜×§×¡×˜ ×××•×—×“ ×œ×—×™×¤×•×©"""
        parts = [
            tool['name'],
            tool['description'],
            tool['category'],
            tool['tags']
        ]
        
        # × ×§×” ×•×—×‘×¨
        search_text = ' '.join([part.strip() for part in parts if part.strip()])
        
        # × ×§×” ××ª×•×•×™× ××™×•×—×“×™×
        search_text = re.sub(r'[^\w\s]', ' ', search_text)
        search_text = re.sub(r'\s+', ' ', search_text).strip()
        
        return search_text
    
    def setup_search_index(self):
        """×‘× ×™×™×ª ××™× ×“×§×¡ ×—×™×¤×•×©"""
        logger.info("ğŸ”§ ×‘×•× ×” ××™× ×“×§×¡ ×—×™×¤×•×© ×¡×× ×˜×™...")
        
        # ×™×¦×•×¨ ×˜×§×¡×˜ ×œ×—×™×¤×•×© ×œ×›×œ ×›×œ×™
        search_texts = []
        for tool in self.tools_data:
            search_text = self.create_search_text(tool)
            search_texts.append(search_text)
        
        # ×™×¦×•×¨ embeddings
        logger.info("âš¡ ×™×•×¦×¨ embeddings...")
        try:
            self.embeddings = self.model.encode(search_texts)
            logger.info(f"âœ… ××™× ×“×§×¡ ×—×™×¤×•×© ××•×›×Ÿ ×¢× {len(self.tools_data)} ×›×œ×™×")
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×™×¦×™×¨×ª embeddings: {e}")
            # ×™×¦×•×¨ embeddings ×“××”
            self.embeddings = np.random.rand(len(self.tools_data), 384)
    
    def preprocess_query(self, query):
        """×¢×™×‘×•×“ ××§×“×™× ×©×œ ×”×©××œ×”"""
        # ×”××¨×” ×œ×× ×’×œ×™×ª ×©×œ ××™×œ×™× × ×¤×•×¦×•×ª ×‘×¢×‘×¨×™×ª
        hebrew_to_english = {
            '×¦\'××˜': 'chat',
            '×¦××˜': 'chat', 
            '×‘×•×˜': 'bot',
            '×ª××•× ×”': 'image',
            '×ª××•× ×•×ª': 'image',
            '×•×™×“××•': 'video',
            '×•×™×“×™×•': 'video',
            '×¡×¨×˜×•×Ÿ': 'video',
            '×˜×§×¡×˜': 'text',
            '×›×ª×™×‘×”': 'writing',
            '×¢×™×¦×•×‘': 'design',
            '×™×¦×™×¨×”': 'generation create',
            '×—×™× ××™': 'free',
            '×‘×—×™× ×': 'free',
            '×‘×ª×©×œ×•×': 'paid',
            '×¢×¨×™×›×”': 'editing',
            '×§×•×“': 'code',
            '×ª×›× ×•×ª': 'programming code',
            '××ª×¨': 'website',
            '×œ×•×’×•': 'logo',
            '××•×¡×™×§×”': 'music',
            '×§×•×œ': 'voice audio',
            '×ª×¨×’×•×': 'translation',
            '×©×¤×”': 'language'
        }
        
        # ×”×—×œ×£ ××™×œ×™× ×‘×¢×‘×¨×™×ª
        for hebrew, english in hebrew_to_english.items():
            query = query.replace(hebrew, english)
        
        # × ×§×”
        query = re.sub(r'[^\w\s]', ' ', query)
        query = re.sub(r'\s+', ' ', query).strip()
        
        return query
    
    def search(self, query, top_k=10):
        """×—×™×¤×•×© ×¡×× ×˜×™"""
        if not query.strip():
            return self.get_random_tools(top_k)
        
        # ×¢×‘×“ ×©××œ×”
        processed_query = self.preprocess_query(query)
        logger.info(f"ğŸ” ××—×¤×©: '{query}' -> '{processed_query}'")
        
        try:
            # ×™×¦×•×¨ embedding ×œ×©××œ×”
            query_embedding = self.model.encode([processed_query])
            
            # ×—×©×‘ ×“××™×•×Ÿ
            similarities = cosine_similarity(query_embedding, self.embeddings)[0]
            
            # ×§×‘×œ ××™× ×“×§×¡×™× ×©×œ ×”×ª×•×¦××•×ª ×”×˜×•×‘×•×ª ×‘×™×•×ª×¨
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            # ×”×›×Ÿ ×ª×•×¦××•×ª
            results = []
            for i, idx in enumerate(top_indices):
                if idx >= len(self.tools_data):
                    continue
                    
                tool = self.tools_data[idx].copy()
                tool['relevance_score'] = float(similarities[idx])
                tool['rank'] = i + 1
                
                # ×—×©×‘ × ×§×•×“×•×ª ×¤×•×¤×•×œ×¨×™×•×ª
                popularity_bonus = 0
                if tool['popularity']:
                    try:
                        pop_num = int(tool['popularity'].replace('+', '').replace(',', ''))
                        popularity_bonus = min(pop_num / 10000, 0.1)  # ××§×¡×™××•× 0.1 ×‘×•× ×•×¡
                    except:
                        pass
                
                tool['final_score'] = similarities[idx] + popularity_bonus
                
                # ×¨×§ ×ª×•×¦××•×ª ×¢× ×¦×™×•×Ÿ ×¡×‘×™×¨
                if tool['final_score'] > 0.1:
                    results.append(tool)
            
            # ××™×™×Ÿ ×œ×¤×™ ×¦×™×•×Ÿ ×¡×•×¤×™
            results.sort(key=lambda x: x['final_score'], reverse=True)
            
            logger.info(f"âœ… × ××¦××• {len(results)} ×ª×•×¦××•×ª")
            return results
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×¤×•×©: {e}")
            return self.get_random_tools(top_k)
    
    def search_by_category(self, category, top_k=20):
        """×—×™×¤×•×© ×œ×¤×™ ×§×˜×’×•×¨×™×”"""
        results = []
        
        for i, tool in enumerate(self.tools_data):
            if category.lower() in tool['category'].lower():
                tool_copy = tool.copy()
                tool_copy['rank'] = len(results) + 1
                tool_copy['relevance_score'] = 1.0
                tool_copy['final_score'] = 1.0
                results.append(tool_copy)
                
                if len(results) >= top_k:
                    break
        
        return results
    
    def get_categories(self):
        """×§×‘×œ×ª ×¨×©×™××ª ×§×˜×’×•×¨×™×•×ª"""
        categories = set()
        for tool in self.tools_data:
            if tool['category']:
                categories.add(tool['category'])
        
        return sorted(list(categories))
    
    def get_random_tools(self, count=10):
        """×›×œ×™× ××§×¨××™×™×"""
        import random
        
        if count >= len(self.tools_data):
            base_tools = self.tools_data
        else:
            base_tools = random.sample(self.tools_data, count)

        tools = []
        for i, tool in enumerate(base_tools):
            tool_copy = tool.copy()
            tool_copy['rank'] = i + 1
            tool_copy['relevance_score'] = 1.0
            tool_copy['final_score'] = 1.0
            tools.append(tool_copy)
        
        return tools
    
    def get_popular_tools(self, top_k=20):
        """×›×œ×™× ×¤×•×¤×•×œ×¨×™×™×"""
        tools_with_pop = []
        
        for tool in self.tools_data:
            if tool['popularity']:
                try:
                    pop_num = int(tool['popularity'].replace('+', '').replace(',', ''))
                    tool_copy = tool.copy()
                    tool_copy['pop_num'] = pop_num
                    tools_with_pop.append(tool_copy)
                except:
                    pass
        
        # ××™×™×Ÿ ×œ×¤×™ ×¤×•×¤×•×œ×¨×™×•×ª
        tools_with_pop.sort(key=lambda x: x['pop_num'], reverse=True)
        
        results = []
        for i, tool in enumerate(tools_with_pop[:top_k]):
            tool['rank'] = i + 1
            tool['relevance_score'] = 1.0
            tool['final_score'] = 1.0
            results.append(tool)
        
        return results
    
    def save_index(self, path='search_index.pkl'):
        """×©××™×¨×ª ××™× ×“×§×¡"""
        try:
            data = {
                'tools_data': self.tools_data,
                'embeddings': self.embeddings.tolist() if self.embeddings is not None else None
            }
            
            with open(path, 'wb') as f:
                pickle.dump(data, f)
            
            logger.info(f"ğŸ’¾ ××™× ×“×§×¡ × ×©××¨ ×‘-{path}")
            return True
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×©××™×¨×ª ××™× ×“×§×¡: {e}")
            return False
    
    def load_index(self, path='search_index.pkl'):
        """×˜×¢×™× ×ª ××™× ×“×§×¡"""
        try:
            with open(path, 'rb') as f:
                data = pickle.load(f)
            
            self.tools_data = data['tools_data']
            if data['embeddings']:
                self.embeddings = np.array(data['embeddings'])
            
            logger.info(f"ğŸ“ ××™× ×“×§×¡ × ×˜×¢×Ÿ ×-{path}")
            return True
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××™× ×“×§×¡: {e}")
            return False

# ×“×•×’×××•×ª ×œ×©×™××•×©
if __name__ == "__main__":
    print("ğŸš€ ×™×•×¦×¨ ×× ×•×¢ ×—×™×¤×•×© AI...")
    
    try:
        # ×™×¦×•×¨ ×× ×•×¢ ×—×™×¤×•×©
        search_engine = AIToolsSemanticSearch()
        
        # ×“×•×’×××•×ª ×—×™×¤×•×©
        test_queries = [
            "×›×œ×™ ×œ×™×¦×™×¨×ª ×ª××•× ×•×ª",
            "×¦'××˜ ×‘×•×˜ ×¢× AI", 
            "×¢×¨×™×›×ª ×•×™×“××•",
            "×™×¦×™×¨×ª ×œ×•×’×•",
            "×ª×¨×’×•× ×©×¤×•×ª",
            "×›×ª×™×‘×ª ×§×•×“",
            "×—×™× ××™"
        ]
        
        print("\nğŸ” ×‘×“×™×§×ª ×—×™×¤×•×©×™×:")
        
        for query in test_queries:
            print(f"\nğŸ“ ×©××œ×”: '{query}'")
            results = search_engine.search(query, top_k=3)
            
            for result in results:
                score = result['final_score']
                print(f"  â€¢ {result['name']} (×¦×™×•×Ÿ: {score:.3f})")
                print(f"    ğŸ“‚ {result['category']} | ğŸ’° {result['pricing']}")
                if result['description']:
                    print(f"    ğŸ“ {result['description'][:100]}...")
        
        # ×©××•×¨ ××™× ×“×§×¡
        search_engine.save_index()
        
        print(f"\nâœ… ×× ×•×¢ ×—×™×¤×•×© ××•×›×Ÿ ×¢× {len(search_engine.tools_data)} ×›×œ×™×!")
        print("ğŸ’¡ ×¢×›×©×™×• ××¤×©×¨ ×œ×‘× ×•×ª ×××©×§ ××©×ª××©")
        
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")
        print("ğŸ’¡ ×”×§×•×“ ×™×¨×•×¥ ×¢× × ×ª×•× ×™× ×“××” ×× ××¡×“ ×”× ×ª×•× ×™× ×œ× ×–××™×Ÿ")
